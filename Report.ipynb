{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d45f076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tabulate\n",
    "# !pip install pytest tabulate hypothesis pandas matplotlib\n",
    "\n",
    "import subprocess\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48f01f16-9ada-45b2-9433-9a05639055b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['set_Right_most_Unset_Bit', 'find_Max', 'get_max_gold', 'sumofFactors', 'first_Digit', 'find_max_val', 'bitonic_subsequence', 'binomial_Coeff', 'max_chain_length', 'sum_Of_Primes', 'max_run_uppercase', 'sort_by_dnf', 'pass_validity', 'check_Type_Of_Triangle', 'count_Pairs', 'generate_matrix', 'rgb_to_hsv', 'max_sub_array_sum', 'get_sum', 'count_duplic', 'is_subset', 'find_first_occurrence', 'longest_increasing_subsequence', 'sum_of_odd_Factors', 'find_longest_conseq_subseq', 'get_Number', 'Sum', 'get_median', 'largest_subset', 'armstrong_number']\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "metadata = []\n",
    "with open(\"bug_portfolio/metadata.jsonl\", \"r\") as f:\n",
    "    buffer = \"\"\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        buffer += line\n",
    "        if line.endswith(\"}\"):\n",
    "            try:\n",
    "                metadata.append(json.loads(buffer))\n",
    "            except json.JSONDecodeError:\n",
    "                pass\n",
    "            buffer = \"\"\n",
    "\n",
    "bug_map = {item[\"name\"]: item.get(\"bug_description\", \"No description provided\") for item in metadata}\n",
    "functions = [item[\"name\"] for item in metadata]\n",
    "\n",
    "# Create mapping from function name to bug description\n",
    "bug_map = {item[\"name\"]: item.get(\"bug_description\", \"No description provided\") for item in metadata}\n",
    "functions = [item[\"name\"] for item in metadata]\n",
    "\n",
    "print(functions)\n",
    "print(len(functions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69e6c02b-467f-47e6-84ae-b29c26f90424",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_counts_from_output(out):\n",
    "    \"\"\"Return (passed, failed) parsed from pytest stdout.\"\"\"\n",
    "    passed = 0\n",
    "    failed = 0\n",
    "    m_passed = re.search(r\"(\\d+)\\s+passed\", out)\n",
    "    m_failed = re.search(r\"(\\d+)\\s+failed\", out)\n",
    "    if m_passed:\n",
    "        passed = int(m_passed.group(1))\n",
    "    if m_failed:\n",
    "        failed = int(m_failed.group(1))\n",
    "    return passed, failed\n",
    "\n",
    "\n",
    "def run_tests(file):\n",
    "    \"\"\"\n",
    "    Run pytest on a single file.\n",
    "    Returns:\n",
    "        exitcode, passed, failed, time_taken_seconds, stdout, stderr\n",
    "    \"\"\"\n",
    "    base = os.path.splitext(os.path.basename(file))[0]\n",
    "    json_file = f\"report_{base}.json\"\n",
    "\n",
    "    # ---- attempt 1: with JSON ----\n",
    "    start = time.perf_counter()\n",
    "\n",
    "    cmd = [\"pytest\", \"-q\", file, \"--json-report\", f\"--json-report-file={json_file}\"]\n",
    "    proc = subprocess.run(cmd, capture_output=True, text=True)\n",
    "\n",
    "    time_taken = time.perf_counter() - start\n",
    "\n",
    "    # If pytest did not generate JSON or errored out → fallback\n",
    "    if proc.returncode == 4 or not os.path.exists(json_file):\n",
    "        # ---- fallback: run WITHOUT json-report ----\n",
    "        start = time.perf_counter()\n",
    "\n",
    "        fallback_cmd = [\"pytest\", \"-q\", file]\n",
    "        proc2 = subprocess.run(fallback_cmd, capture_output=True, text=True)\n",
    "\n",
    "        time_taken = time.perf_counter() - start\n",
    "\n",
    "        passed, failed = parse_counts_from_output(proc2.stdout)\n",
    "        return proc2.returncode, passed, failed, time_taken, proc2.stdout, proc2.stderr\n",
    "\n",
    "    # ---- JSON successfully created: extract summary ----\n",
    "    try:\n",
    "        with open(json_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "        summary = data.get(\"summary\", {})\n",
    "        passed = summary.get(\"passed\", 0)\n",
    "        failed = summary.get(\"failed\", 0)\n",
    "    except Exception:\n",
    "        # fallback to parsing stdout\n",
    "        passed, failed = parse_counts_from_output(proc.stdout)\n",
    "    finally:\n",
    "        try:\n",
    "            os.remove(json_file)\n",
    "        except OSError:\n",
    "            pass\n",
    "\n",
    "    return proc.returncode, passed, failed, time_taken, proc.stdout, proc.stderr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c47baa-499b-4d27-a085-efb513a09503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing `set_Right_most_Unset_Bit` ===\n",
      "Bug Description: When n = 0, the function returns 0 instead of 1\n",
      "LLM tests for `set_Right_most_Unset_Bit`: Bug found (exit code 1)\n",
      "LLM Summary: 12 passed, 1 failed (time: 2.15s)\n",
      "Human tests for `set_Right_most_Unset_Bit`: Bug found (exit code 1)\n",
      "Human Summary: 3 passed, 2 failed (time: 2.86s)\n",
      "\n",
      "=== Testing `find_Max` ===\n",
      "Bug Description: the condition if (arr[low] >= arr[mid]) should be if (arr[low] > arr[mid]), as using >= can cause incorrect recursion and miss the maximum element in certain cases.\n",
      "LLM tests for `find_Max`: Bug not found (exit code 0)\n",
      "LLM Summary: 10 passed, 0 failed (time: 1.93s)\n",
      "Human tests for `find_Max`: Bug found (exit code 1)\n",
      "Human Summary: 2 passed, 3 failed (time: 3.08s)\n",
      "\n",
      "=== Testing `get_max_gold` ===\n",
      "Bug Description: The final answer calculation loop doesn't check for the last row's first element. ie loop is running till m-2\n",
      "LLM tests for `get_max_gold`: Bug found (exit code 1)\n",
      "LLM Summary: 7 passed, 2 failed (time: 2.08s)\n",
      "Human tests for `get_max_gold`: Bug found (exit code 1)\n",
      "Human Summary: 4 passed, 1 failed (time: 3.36s)\n",
      "\n",
      "=== Testing `sumofFactors` ===\n",
      "Bug Description: The function doesn't correctly handle the case when n is 2. It should return 2 as the sum of even factors but due to a missing condition, it returns 3 instead.\n",
      "LLM tests for `sumofFactors`: Bug found (exit code 1)\n",
      "LLM Summary: 11 passed, 1 failed (time: 2.05s)\n",
      "Human tests for `sumofFactors`: Bug found (exit code 1)\n",
      "Human Summary: 4 passed, 1 failed (time: 3.37s)\n",
      "\n",
      "=== Testing `first_Digit` ===\n",
      "Bug Description:  The while loop that removes trailing digits runs only while fact is greater than 10, which causes it to stop prematurely when fact is exactly 10, leading to incorrect results for certain inputs.\n",
      "LLM tests for `first_Digit`: Bug not found (exit code 0)\n",
      "LLM Summary: 12 passed, 0 failed (time: 1.99s)\n",
      "Human tests for `first_Digit`: Bug found (exit code 1)\n",
      "Human Summary: 4 passed, 3 failed (time: 3.10s)\n",
      "\n",
      "=== Testing `find_max_val` ===\n",
      "Bug Description: return (ans if (ans > 0 and ans <= n) else -1) should be return (ans if (ans >= 0 and ans <= n) else -1) to correctly handle the case when k = 0 is a valid solution.\n",
      "LLM tests for `find_max_val`: Bug not found (exit code 0)\n",
      "LLM Summary: 11 passed, 0 failed (time: 1.81s)\n",
      "Human tests for `find_max_val`: Bug not found (exit code 0)\n",
      "Human Summary: 6 passed, 0 failed (time: 4.81s)\n",
      "\n",
      "=== Testing `bitonic_subsequence` ===\n",
      "Bug Description: Changed the strict inequality operator > to non-strict inequality operator >= in the Longest Increasing Subsequence (LIS) comparison on line 6. The condition was changed from arr[i] > arr[j] to arr[i] >= arr[j].\n",
      "LLM tests for `bitonic_subsequence`: Bug found (exit code 1)\n",
      "LLM Summary: 8 passed, 4 failed (time: 2.09s)\n",
      "Human tests for `bitonic_subsequence`: Bug not found (exit code 0)\n",
      "Human Summary: 8 passed, 0 failed (time: 3.98s)\n",
      "\n",
      "=== Testing `binomial_Coeff` ===\n",
      "Bug Description: The function is called with incorrect parameters in sum_Of_product. Changed binomial_Coeff(2 * n, n - 1) to binomial_Coeff(2 * n, n).\n",
      "LLM tests for `binomial_Coeff`: Bug found (exit code 1)\n",
      "LLM Summary: 7 passed, 3 failed (time: 2.24s)\n",
      "Human tests for `binomial_Coeff`: Bug found (exit code 1)\n",
      "Human Summary: 10 passed, 2 failed (time: 3.83s)\n",
      "\n",
      "=== Testing `max_chain_length` ===\n",
      "Bug Description: Changed the strict inequality operator > to non-strict inequality operator >= in the chain comparison condition. Changed arr[i].a > arr[j].b to arr[i].a >= arr[j].b.\n",
      "LLM tests for `max_chain_length`: Bug not found (exit code 0)\n",
      "LLM Summary: 10 passed, 0 failed (time: 2.07s)\n",
      "Human tests for `max_chain_length`: Bug not found (exit code 0)\n",
      "Human Summary: 14 passed, 0 failed (time: 4.42s)\n",
      "\n",
      "=== Testing `sum_Of_Primes` ===\n",
      "Bug Description:  The condition in the while loop should be 'while p * p <= n:' instead of 'while p * p < n:'. This change is necessary to ensure that all prime factors up to the square root of n are considered, including the case when p * p equals n.\n",
      "LLM tests for `sum_Of_Primes`: Bug not found (exit code 0)\n",
      "LLM Summary: 17 passed, 0 failed (time: 2.02s)\n",
      "Human tests for `sum_Of_Primes`: Bug found (exit code 1)\n",
      "Human Summary: 6 passed, 2 failed (time: 3.50s)\n",
      "\n",
      "=== Testing `max_run_uppercase` ===\n",
      "Bug Description:  In the else block, the line 'cnt = -1' incorrectly resets the count of consecutive uppercase characters to -1 instead of 0. This causes the function to undercount the length of uppercase runs following a non-uppercase character.\n",
      "LLM tests for `max_run_uppercase`: Bug found (exit code 1)\n",
      "LLM Summary: 8 passed, 6 failed (time: 2.27s)\n",
      "Human tests for `max_run_uppercase`: Bug found (exit code 1)\n",
      "Human Summary: 7 passed, 4 failed (time: 3.92s)\n",
      "\n",
      "=== Testing `sort_by_dnf` ===\n",
      "Bug Description:  In the case where arr[mid] == 1, the line 'mid = mid + 2' incorrectly increments mid by 2 instead of 1.\n",
      "LLM tests for `sort_by_dnf`: Bug not found (exit code 0)\n",
      "LLM Summary: 13 passed, 0 failed (time: 2.07s)\n",
      "Human tests for `sort_by_dnf`: Bug found (exit code 1)\n",
      "Human Summary: 8 passed, 5 failed (time: 4.72s)\n",
      "\n",
      "=== Testing `pass_validity` ===\n",
      "Bug Description: In  the line checking for whitespace characters, the regex pattern is incorrectly written as '\\s ' (with an extra space) instead of '\\s'. This causes the function to fail to identify passwords that contain whitespace characters, leading to incorrect validation results.\n",
      "LLM tests for `pass_validity`: Bug found (exit code 1)\n",
      "LLM Summary: 17 passed, 4 failed (time: 2.28s)\n",
      "Human tests for `pass_validity`: Bug found (exit code 1)\n",
      "Human Summary: 10 passed, 1 failed (time: 5.07s)\n",
      "\n",
      "=== Testing `check_Type_Of_Triangle` ===\n",
      "Bug Description:  The condition to check for a right-angled triangle is incorrect. It should use addition for all comparisons instead of subtraction. The correct condition is 'if (sqa == sqb + sqc or sqb == sqa + sqc or sqc == sqa + sqb):' to properly apply the Pythagorean theorem. \n",
      "LLM tests for `check_Type_Of_Triangle`: Bug found (exit code 1)\n",
      "LLM Summary: 6 passed, 5 failed (time: 2.16s)\n",
      "Human tests for `check_Type_Of_Triangle`: Bug found (exit code 1)\n",
      "Human Summary: 7 passed, 2 failed (time: 4.25s)\n",
      "\n",
      "=== Testing `count_Pairs` ===\n",
      "Bug Description: The inner loop should iterate from i+1 to n instead of i+1 to n-1 to ensure all elements are considered.\n",
      "LLM tests for `count_Pairs`: Bug found (exit code 1)\n",
      "LLM Summary: 4 passed, 7 failed (time: 2.20s)\n"
     ]
    }
   ],
   "source": [
    "llm_found = {}\n",
    "human_found = {}\n",
    "\n",
    "for func in functions:\n",
    "    print(f\"\\n=== Testing `{func}` ===\")\n",
    "    print(f\"Bug Description: {bug_map[func]}\")\n",
    "\n",
    "    # LLM tests\n",
    "    llm_file = f\"llm_tests/generated_tests/test_{func}.py\"\n",
    "    llm_exitcode, llm_passed, llm_failed, llm_time, llm_out, llm_err = run_tests(llm_file)\n",
    "\n",
    "    llm_status = \"found\" if llm_exitcode != 0 else \"not found\"\n",
    "    llm_found[func] = (llm_exitcode != 0)\n",
    "    print(f\"LLM tests for `{func}`: Bug {llm_status} (exit code {llm_exitcode})\")\n",
    "    print(f\"LLM Summary: {llm_passed} passed, {llm_failed} failed (time: {llm_time:.2f}s)\")\n",
    "\n",
    "    # Human tests\n",
    "    human_file = f\"human_tests/test_{func}.py\"\n",
    "    human_exitcode, human_passed, human_failed, human_time, human_out, human_err = run_tests(human_file)\n",
    "\n",
    "    human_status = \"found\" if human_exitcode != 0 else \"not found\"\n",
    "    human_found[func] = (human_exitcode != 0)\n",
    "    print(f\"Human tests for `{func}`: Bug {human_status} (exit code {human_exitcode})\")\n",
    "    print(f\"Human Summary: {human_passed} passed, {human_failed} failed (time: {human_time:.2f}s)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e22c90-6fe8-41f7-b563-9a695bb6a096",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for func in functions:\n",
    "    results.append({\n",
    "        \"Function\": func,\n",
    "        \"LLM Found\": \"Yes\" if llm_found.get(func, False) else \"No\",\n",
    "        \"Human Found\": \"Yes\" if human_found.get(func, False) else \"No\"\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "\n",
    "\n",
    "# Manually update any function’s results here:\n",
    "# df.loc[df['Function'] == 'gold_mine_problem', 'LLM Found'] = 'No'\n",
    "# df.loc[df['Function'] == 'set_Right_most_Unset_Bit', 'Human Found'] = 'Yes'\n",
    "# Uncomment and edit as needed\n",
    "\n",
    "# ---- Manual overrides go here ----\n",
    "# df.loc[df['Function'] == 'gold_mine_problem', 'LLM Found'] = 'No'\n",
    "# df.loc[df['Function'] == 'set_Right_most_Unset_Bit', 'Human Found'] = 'Yes'\n",
    "# ----------------------------------\n",
    "\n",
    "print(\"### Individual Test Results\\n\")\n",
    "print(df.to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcf606f-f99c-4972-8e1f-b0ae5eb4ca40",
   "metadata": {},
   "outputs": [],
   "source": [
    "only_llm = ((df[\"LLM Found\"] == \"Yes\") & (df[\"Human Found\"] == \"No\")).sum()\n",
    "only_human = ((df[\"LLM Found\"] == \"No\") & (df[\"Human Found\"] == \"Yes\")).sum()\n",
    "both = ((df[\"LLM Found\"] == \"Yes\") & (df[\"Human Found\"] == \"Yes\")).sum()\n",
    "neither = ((df[\"LLM Found\"] == \"No\") & (df[\"Human Found\"] == \"No\")).sum()\n",
    "\n",
    "total = len(df)\n",
    "\n",
    "# Overall detection percentages\n",
    "llm_total_found = only_llm + both\n",
    "human_total_found = only_human + both\n",
    "\n",
    "llm_overall_percentage = round((llm_total_found / total) * 100, 2)\n",
    "human_overall_percentage = round((human_total_found / total) * 100, 2)\n",
    "\n",
    "scorecard = pd.DataFrame({\n",
    "    \"Metric\": [\n",
    "        \"Bugs found only by LLM tests\",\n",
    "        \"Bugs found only by Human properties\",\n",
    "        \"Bugs found by both\",\n",
    "        \"Bugs found by neither\"\n",
    "    ],\n",
    "    \"Count\": [only_llm, only_human, both, neither],\n",
    "})\n",
    "\n",
    "# Add percentage column\n",
    "scorecard[\"Percentage\"] = (scorecard[\"Count\"] / total * 100).round(2).astype(str) + \"%\"\n",
    "\n",
    "print(\"\\n\\n### Final Scorecard\\n\")\n",
    "print(scorecard.to_markdown(index=False))\n",
    "\n",
    "print(\"\\n### Overall Detection Rates\\n\")\n",
    "print(f\"LLM Overall Detection: {llm_total_found}/{total} = {llm_overall_percentage}%\")\n",
    "print(f\"Human Overall Detection: {human_total_found}/{total} = {human_overall_percentage}%\")\n",
    "\n",
    "# Save CSVs\n",
    "df.to_csv(\"results_summary.csv\", index=False)\n",
    "scorecard.to_csv(\"final_scorecard.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c338336e-7fe7-4ca8-acd7-0d3ae341d813",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5))\n",
    "plt.bar(scorecard[\"Metric\"], scorecard[\"Count\"])\n",
    "plt.title(\"Bug Detection Summary (LLM vs Human)\")\n",
    "plt.ylabel(\"Number of Bugs Found\")\n",
    "plt.xticks(rotation=20, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe446c3-3158-4f63-ba01-8c8fff1a1127",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6769ead-d982-428f-855a-6f6a0673764d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a618818-c94b-4daf-9ab8-01a0dbfddb51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
